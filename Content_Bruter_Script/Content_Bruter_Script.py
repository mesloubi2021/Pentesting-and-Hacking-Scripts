import queue
import threading
import urllib.request
import urllib.error
import urllib.parse

threads = 50
target_url = "http://testphp.vulnweb.com"
wordlist_file = "all.txt"
resume = None
user_agent = "Mozilla/5.0 (X11; Linux x86_64; rv:19.0) Gecko/20100101 Firefox/19.0"


def build_wordlist(wordlst_file):
    with open(wordlst_file, "r") as fd:
        raw_words = [line.strip() for line in fd]

    words = queue.Queue()
    found_resume = not bool(resume)

    for word in raw_words:
        if found_resume or word == resume:
            words.put(word)
            found_resume = True

    return words


def dir_bruter(extensions=None):
    while not word_queue.empty():
        attempt = word_queue.get()
        attempt_list = [f"/{attempt}/"] if "." not in attempt else [f"/{attempt}"]

        if extensions:
            attempt_list.extend([f"/{attempt}{extension}" for extension in extensions])

        for brute in attempt_list:
            url = f"{target_url}{urllib.parse.quote(brute)}"
            try:
                headers = {"User-Agent": user_agent}
                r = urllib.request.Request(url, headers=headers)
                response = urllib.request.urlopen(r)
                if len(response.read()):
                    print(f"[{response.code}] => {url}")
            except urllib.error.HTTPError as e:
                if e.code != 404:
                    print(f"!!! {e.code} => {url}")


word_queue = build_wordlist(wordlist_file)
file_extensions = [".php", ".bak", ".orig", ".inc"]

for _ in range(threads):
    t = threading.Thread(target=dir_bruter, args=(file_extensions,))
    t.start()
